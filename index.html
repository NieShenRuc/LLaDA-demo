<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8" />
        <meta name="description" content="DESCRIPTION META TAG" />
        <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
        <meta
            property="og:description"
            content="SOCIAL MEDIA DESCRIPTION TAG TAG"
        />
        <meta property="og:url" content="URL OF THE WEBSITE" />

        <meta
            property="og:image"
            content="static/image/your_banner_image.png"
        />
        <meta property="og:image:width" content="1200" />
        <meta property="og:image:height" content="630" />

        <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG" />
        <meta
            name="twitter:description"
            content="TWITTER BANNER DESCRIPTION META TAG"
        />

        <meta
            name="twitter:image"
            content="static/images/your_twitter_banner_image.png"
        />
        <meta name="twitter:card" content="summary_large_image" />

        <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />

        <title>Large Language Diffusion Models</title>
        <link rel="icon" type="image/x-icon" href="static/images/favicon.ico" />
        <link
            href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
            rel="stylesheet"
        />

        <link rel="stylesheet" href="static/css/bulma.min.css" />
        <link rel="stylesheet" href="static/css/bulma-carousel.min.css" />
        <link rel="stylesheet" href="static/css/bulma-slider.min.css" />
        <link rel="stylesheet" href="static/css/fontawesome.all.min.css" />
        <link
            rel="stylesheet"
            href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css"
        />
        <link rel="stylesheet" href="static/css/index.css" />

        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
        <script defer src="static/js/fontawesome.all.min.js"></script>
        <script src="static/js/bulma-carousel.min.js"></script>
        <script src="static/js/bulma-slider.min.js"></script>
        <script src="static/js/index.js"></script>

        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </head>

    <body>
        <section class="hero">
            <div class="hero-body">
                <div class="container is-max-desktop">
                    <div class="columns is-centered">
                        <div class="column has-text-centered">
                            <h1 class="title is-1 publication-title">
                                Large Language Diffusion Models
                            </h1>

                            <div class="is-size-5 publication-authors">
                                <span class="author-block">
                                    <a
                                        href="https://scholar.google.com/citations?user=mVaNdrsAAAAJ"
                                        target="_blank"
                                        >Shen Nie</a
                                    ><sup>1</sup>,</span
                                >
                                <span class="author-block">
                                    <a href="" target="_blank">Fengqi Zhu</a
                                    ><sup>1</sup>,</span
                                >
                                <span class="author-block">
                                    <a
                                        href="https://yyyouy.github.io/"
                                        target="_blank"
                                        >Zebin You</a
                                    ><sup>1</sup>,</span
                                >
                                <span class="author-block">
                                    <a
                                        href="https://scholar.google.com/citations?user=cAz9PToAAAAJ"
                                        target="_blank"
                                        >Xiaolu Zhang</a
                                    ><sup>2</sup>,</span
                                >
                                <span class="author-block">
                                    <a href="" target="_blank">Jingyang Ou</a
                                    ><sup>1</sup>,</span
                                >
                                <span class="author-block">
                                    <a href="" target="_blank">Jun Hu</a
                                    ><sup>2</sup>,</span
                                >
                                <span class="author-block">
                                    <a
                                        href="https://scholar.google.com/citations?user=mCVvloEAAAAJ"
                                        target="_blank"
                                        >Jun Zhou</a
                                    ><sup>2</sup>,</span
                                >
                                <span class="author-block">
                                    <a
                                        href="https://scholar.google.com/citations?user=j8K1FqEAAAAJ"
                                        target="_blank"
                                        >Yankai Lin</a
                                    ><sup>1</sup>,</span
                                >
                                <span class="author-block">
                                    <a
                                        href="https://scholar.google.com/citations?user=tbxCHJgAAAAJ"
                                        target="_blank"
                                        >Ji-Rong Wen</a
                                    ><sup>1</sup>,</span
                                >
                                <span class="author-block">
                                    <a
                                        href="https://zhenxuan00.github.io/"
                                        target="_blank"
                                        >Chongxuan Li</a
                                    ><sup>1</sup></span
                                >
                            </div>

                            <div class="is-size-5 publication-authors">
                                <span class="author-block"
                                    ><sup>1</sup>Renmin University of
                                    China,</span
                                >
                                <span class="author-block"
                                    ><sup>2</sup>Ant Group</span
                                >
                            </div>

                            <div class="column has-text-centered">
                                <div class="publication-links">
                                    <span class="link-block">
                                        <a
                                            href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf"
                                            target="_blank"
                                            class="external-link button is-normal is-rounded is-dark"
                                        >
                                            <span class="icon">
                                                <i class="fas fa-file-pdf"></i>
                                            </span>
                                            <span>Paper</span>
                                        </a>
                                    </span>

                                    <span class="link-block">
                                        <a
                                            href="https://github.com/YOUR REPO HERE"
                                            target="_blank"
                                            class="external-link button is-normal is-rounded is-dark"
                                        >
                                            <span class="icon">
                                                <i class="fab fa-github"></i>
                                            </span>
                                            <span>Code</span>
                                        </a>
                                    </span>

                                    <span class="link-block">
                                        <a
                                            href="https://github.com/YOUR REPO HERE"
                                            target="_blank"
                                            class="external-link button is-normal is-rounded is-dark"
                                        >
                                            <span class="icon">ü§ó</span>
                                            <span>Model</span>
                                        </a>
                                    </span>
                                </div>
                            </div>

                            <!-- TL;DR Section -->
                            <div class="notification is-light is-size-5 has-text-centered" style="padding: 15px; margin-top: 20px;">
                                <strong>TL;DR:</strong> <span style="color: #1E88E5;">We present LLaDA, a 8B parameters diffusion  language model trained from scratch that is competitive to LLaMA 3.</span>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </section>

        <section class="hero is-small">
            <div class="hero-body">
                <div
                    class="container"
                    style="
                        display: flex;
                        justify-content: space-around;
                        gap: 20px;
                    "
                >
                    <div class="item" style="text-align: center">
                        <img
                            src="static/images/LLaDA_vs_LLaMA.svg"
                            alt="LLaDA_vs_LLaMA"
                        />
                    </div>
                    <div class="item" style="text-align: center">
                        <img
                            src="static/images/LLaDA_vs_LLaMA_chat.svg"
                            alt="LLaDA_vs_LLaMA_chat"
                        />
                    </div>
                </div>
            </div>
        </section>

        <section
            class="section"
            id="Intro"
            style="text-align: center; font-weight: bold; position: relative; padding: 50px 20px;"
        >
            <div
            style="
                width: 100%;
                height: 1px;
                background-color: rgba(0, 0, 0, 0.1);
                margin: 0 auto 15px auto;
                "
            ></div>
            <div
                class="container is-max-desktop content"
                style="position: relative; font-size: 1.5rem; color: #1E88E5; text-shadow: 2px 2px 5px rgba(0, 0, 0, 0.2); font-style: italic;"
        >
            What is now proved was once only imagined.   ‚Äî‚Äî‚Äî William Blake
            </div>
            <div
                style="
                    position: absolute;
                    bottom: -10px;
                    right: 50px;
                    font-weight: bold;
                    font-size: 1rem;
                    color: #666;
                    font-style: italic;
                "
            >
            </div>
        </section>

        <section class="section" id="Introduction">
            <div class="container is-max-desktop content">
                <h2 class="title">Motivation</h2>
                <blockquote
                    style="font-size: 1.4rem; font-weight: bold; color: #333; text-align: center; margin: 20px 0; padding: 15px; border-left: 4px solid #1E88E5; background: rgba(30, 136, 229, 0.05);"
                >
                    Compression is Intelligence.   ‚Äî‚Äî‚Äî Ilya Sutskever
                </blockquote>

                <p style="font-size: 1.7rem; font-family: 'Times New Roman', Times, serif;">
                    We assume that large language models derive their intelligence not from the autoregressive
                    mechanism itself, but from the fundamental principle of generative modeling‚Äîapproximating
                    the true language distribution via maximum likelihood estimation or KL divergence minimization.
                </p>
                <img
                    src="static/images/min_kl.svg"
                    alt="min_kl"
                    style="
                        width: 80%;
                        height: auto;
                        margin-bottom: 2px;
                        margin-left: 10%;
                    "
                />

                <h2 class="title">Method</h2>

                <p style="font-size: 1.7rem; font-family: 'Times New Roman', Times, serif;">
                    LLaDA is a masked diffusion model [1, 2, 3] that employs the following methods
                    for pre-training, supervised fine-tuning, and sampling.
                </p>
            </div>

            <div style="width: 100%; max-width: 1400px; margin: 0 auto; overflow: hidden;">
                <img
                    src="static/images/method.png"
                    alt="min_kl"
                    style="width: 100%; height: auto; display: block; margin-bottom: 30px;"
                />
            </div>

            <div class="container is-max-desktop content">
                <h2 class="title">Scalability</h2>
                <p style="font-size: 1.7rem; font-family: 'Times New Roman', Times, serif;">
                    LLaDA demonstrates impressive scalability, with its overall
                    trend being highly competitive with that of autoregressive baseline.
                </p>

            </div>

            <div class="image-gallery">
                <div class="row">
                    <img
                        src="static/images/scaling_mmlu.svg"
                        alt="scaling_mmlu"
                        style="
                            width: 25%;
                            height: auto;
                            margin-bottom: 20px;
                            margin-left: 150px;
                        "
                    />
                    <img
                        src="static/images/scaling_arc_c.svg"
                        alt="scaling_arc_c"
                        style="width: 25%; height: auto; margin-bottom: 20px"
                    />
                    <img
                        src="static/images/scaling_cmmlu.svg"
                        alt="scaling_cmmlu"
                        style="width: 25%; height: auto; margin-bottom: 20px"
                    />
                </div>
                <div class="row">
                    <img
                        src="static/images/scaling_piqa.svg"
                        alt="scaling_piqa"
                        style="
                            width: 25%;
                            height: auto;
                            margin-bottom: 20px;
                            margin-left: 150px;
                        "
                    />
                    <img
                        src="static/images/scaling_gsm8k.svg"
                        alt="scaling_gsm8k"
                        style="width: 25%; height: auto; margin-bottom: 20px"
                    />
                    <img
                        src="static/images/scaling_humaneval.svg"
                        alt="scaling_humaneval"
                        style="width: 25%; height: auto; margin-bottom: 20px"
                    />
                </div>
            </div>

        </section>


        <section class="section" id="Sampling Process" style="text-align: center;">
            <div
            style="
                width: 100%;
                height: 1px;
                background-color: rgba(0, 0, 0, 0.1);
                margin: 0 auto 15px auto;
                "
            ></div>

            <h2 class="title">Sampling process of LLaDA Instruct</h2>

            <p style="font-size: 1.5rem; font-family: 'Times New Roman', Times, serif;">
                Prompt: <i>Lily can run 12 kilometers per hour for 4 hours. After that,
                she runs 6 kilometers per hour. How many kilometers can she run in 8 hours?</i>
            </p>

            <img
                src="static/images/diff.gif"
                alt="diff.gif"
                style="width: 60%; height: auto; display: block; margin-bottom: 30px; margin-left: auto; margin-right: auto;"
            />

            <p style="font-size: 1.5rem; font-family: 'Times New Roman', Times, serif;">
                We replace the |MASK| tokens with the clean data prediction results during sampling.
            </p>

            <img
                src="static/images/diff_remask.gif"
                alt="diff_remask.gif"
                style="width: 60%; height: auto; display: block; margin-bottom: 30px; margin-left: auto; margin-right: auto;"
            />

            <p style="font-size: 1.5rem; font-family: 'Times New Roman', Times, serif;">
                LLaDA can generate in a next-token prediction manner.
            </p>

            <img
                src="static/images/ar.gif"
                alt="ar.gif"
                style="width: 60%; height: auto; display: block; margin-bottom: 30px; margin-left: auto; margin-right: auto;"
            />

            <p style="font-size: 1.5rem; font-family: 'Times New Roman', Times, serif;">
                LLaDA can generate in a semi-autoregressive manner.
            </p>

            <img
                src="static/images/sar.gif"
                alt="sar.gif"
                style="width: 60%; height: auto; display: block; margin-bottom: 30px; margin-left: auto; margin-right: auto;"
            />

        </section>


<!--        <section class="section" id="Case study">-->
<!--            <div class="container is-max-desktop content">-->
<!--                <h2 class="title">Cases</h2>-->
<!--                <h3 class="title">Single-turn Dialogue</h3>-->
<!--                <table>-->
<!--                    <tr>-->
<!--                        <th>Math dialogue</th>-->
<!--                        <td></td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>User</th>-->
<!--                        <td>-->
<!--                            Emma decides to run 4 sprints 5 times a week. She-->
<!--                            runs 75 meters each sprint. How many total meters-->
<!--                            does she run a week?-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>LLaDA-Instruct</th>-->
<!--                        <td>-->
<!--                            Emma runs 4 sprints each time, so she runs a total-->
<!--                            of 4 x 5 = 20 sprints a week. Each sprint is 75-->
<!--                            meters long, so Emma runs a total of 20 x 75 = 1500-->
<!--                            meters a week. The final result is 1500-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                </table>-->
<!--                <hr />-->
<!--                <table>-->
<!--                    <tr>-->
<!--                        <th>Code dialogue</th>-->
<!--                        <td></td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>User</th>-->
<!--                        <td>-->
<!--                            I am writing python code, I have an array, please-->
<!--                            help me sort it from largest to smallest-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>LLaDA-Instruct</th>-->
<!--                        <td>-->
<!--                            Certainly! You can sort an array from the largest to-->
<!--                            smallest in Python using the ‚Äòsort()‚Äô method or the-->
<!--                            ‚Äòsorted()‚Äò function. Here‚Äôs an example: <br />-->
<!--                            ### Using ‚Äòsort()‚Äô method: <br />my array = [3, 1,-->
<!--                            4, 1, 5, 2] <br />my array.sort(reverse=True)<br />-->
<!--                            print(my array)-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                </table>-->
<!--                <hr />-->
<!--                <table>-->
<!--                    <tr>-->
<!--                        <th>Translation dialogue</th>-->
<!--                        <td></td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>User</th>-->
<!--                        <td>-->
<!--                            Please help me translate into Chinese: ‚ÄòWhat is now-->
<!--                            proved was once only imagined‚Äô-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>LLaDA-Instruct</th>-->
<!--                        <td>Áé∞Âú®Ë¢´ËØÅÊòéÁöÑÊõæÁªèÂè™ÊòØÊÉ≥Ë±°</td>-->
<!--                    </tr>-->
<!--                </table>-->
<!--                <hr />-->
<!--                <table>-->
<!--                    <tr>-->
<!--                        <th>Translation dialogue</th>-->
<!--                        <td></td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>User</th>-->
<!--                        <td>-->
<!--                            Please help me translate into German: ‚ÄòWhat is now-->
<!--                            proved was once only imagined‚Äô-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>LLaDA-Instruct</th>-->
<!--                        <td>-->
<!--                            Wer heute best√§tigt ist, war einst nur immaginiert.-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                </table>-->

<!--                <h3 class="title">Multi-turn Dialogue</h3>-->
<!--                <table>-->
<!--                    <tr>-->
<!--                        <th>Daily life dialogue</th>-->
<!--                        <td></td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>User</th>-->
<!--                        <td>How do I start learning programming?</td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>LLaDA-Instruct</th>-->
<!--                        <td>-->
<!--                            To learn programming, you can start by choosing a-->
<!--                            programming language that you are interested in.-->
<!--                            Some popular languages include Python, Java, and-->
<!--                            C++.-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>User</th>-->
<!--                        <td>-->
<!--                            Which programming language should I learn first?-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>LLaDA-Instruct</th>-->
<!--                        <td>-->
<!--                            It depends on your interests and goals. Python is a-->
<!--                            great language for beginners for its simplicity and-->
<!--                            versatility.-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>User</th>-->
<!--                        <td>How long does it take to learn Python?</td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>LLaDA-Instruct</th>-->
<!--                        <td>-->
<!--                            It can take anywhere from a few weeks to several-->
<!--                            months to learn Python.-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>User</th>-->
<!--                        <td>-->
<!--                            What are some good Python projects for beginners?-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>LLaDA-Instruct</th>-->
<!--                        <td>-->
<!--                            Some good Python projects for beginners include-->
<!--                            building a simple calculator, a game, and a web-->
<!--                            application.-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                </table>-->
<!--                <hr />-->
<!--                <table>-->
<!--                    <tr>-->
<!--                        <th>Math dialogue</th>-->
<!--                        <td></td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>User</th>-->
<!--                        <td>-->
<!--                            Natalia sold clips to 48 of her friends in April,-->
<!--                            and then she sold half as many clips in May. How-->
<!--                            many clips did Natalia sell altogether in April and-->
<!--                            May?-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>LLaDA-Instruct</th>-->
<!--                        <td>-->
<!--                            Natalia sold clips to 48 friends in April. She sold-->
<!--                            half as many clips in May, so she sold 48/2 = 24-->
<!--                            clips in May. Altogether, Natalia sold 48 + 24 = 72-->
<!--                            clips in April and May. The final result is 72.-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>User</th>-->
<!--                        <td>-->
<!--                            Natalia sold three times as many items in June as-->
<!--                            she did in May. How many clips did Natalia sell-->
<!--                            altogether in these three months?-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>LLaDA-Instruct</th>-->
<!--                        <td>-->
<!--                            Natalia sold clips to 48 friends in April. She sold-->
<!--                            half as many clips in May, so she sold 48/2 = 24-->
<!--                            clips in May. Natalia sold three times as many items-->
<!--                            in June as she did in May, so she sold 24 * 3 = 72-->
<!--                            clips in June. Altogether, Natalia sold 48 + 24 + 72-->
<!--                            = 144 clips in these three months. The final result-->
<!--                            is 144.-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                </table>-->
<!--                <h3 class="title">Poem Reversal Completion</h3>-->
<!--                <table>-->
<!--                    <tr>-->
<!--                        <th>Q1</th>-->
<!--                        <td></td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>User</th>-->
<!--                        <td>‚Äò‰ΩÜÈóª‰∫∫ËØ≠Âìç‚ÄôÁöÑ‰∏ä‰∏ÄÂè•ÊòØ‰ªÄ‰πà?</td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>GPT-4o</th>-->
<!--                        <td>-->
<!--                            ‚Äú‰ΩÜÈóª‰∫∫ËØ≠Âìç‚ÄùÁöÑ‰∏ä‰∏ÄÂè•ÊòØ‚ÄúÊó†ÂèØÂ•à‰ΩïËä±ËêΩÂéª‚Äù,Ëøô‰∏§Âè•Âá∫Ëá™Âîê‰ª£ËØç‰∫∫ÊùéÊ∏ÖÁÖßÁöÑÔºàÊ≠¶ÈôµÊò•ÔºåÊò•Êôö:-->
<!--                            Êó†ÂèØÂ•à‰ΩïËä±ËêΩÂéªÔºå‰ΩÜÈóª‰∫∫ËØ≠Âìç„ÄÇËøôÈ¶ñËØçË°®Ëææ‰∫Ü‰ΩúËÄÖÂú®Êò•Â§©Êó∂ËäÇÁöÑÂ≠§Áã¨‰∏é-->
<!--                            ÊÑü‰º§ÔºåÂÄüËä±ËêΩÂíå‰∫∫ËØ≠Â£∞ÁöÑÊèèÂÜôÔºåÂèçÊò†Âá∫ËØç‰∫∫ÂÜÖÂøÉÁöÑÊó†‰∫≤‰∏éÂ§±ËêΩ„ÄÇ-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>LLaDA-Instruct</th>-->
<!--                        <td>‚Äú‰ΩÜÈóª‰∫∫ËØ≠Âìç‚ÄùÁöÑ‰∏ä‰∏ÄÂè•ÊòØ‚ÄúÁ©∫Â±±‰∏çËßÅ‰∫∫‚Äù</td>-->
<!--                    </tr>-->
<!--                </table>-->
<!--                <hr />-->
<!--                <table>-->
<!--                    <tr>-->
<!--                        <th>Q2</th>-->
<!--                        <td></td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>User</th>-->
<!--                        <td>‚ÄòÂ§úÈùôÊò•Â±±Á©∫‚ÄôÁöÑ‰∏ä‰∏ÄÂè•ÊòØ‰ªÄ‰πà?</td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>GPT-4o</th>-->
<!--                        <td>-->
<!--                            ‚ÄúÂ§úÈùôÊò•Â±±Á©∫‚ÄùÁöÑ‰∏ä‰∏ÄÂè•ÊòØ‚ÄúÁ©∫Â±±Êñ∞Èõ®Âêé‚Äù.Ëøô‰∏§Âè•Âá∫Ëá™Âîê‰ª£ËØó‰∫∫ÁéãÁª¥ÁöÑÔºàÂ±±Â±ÖÁßã-->
<!--                            ËÜúÔºâ:Á©∫Â±±Êñ∞Èõ®ÂêéÔºåÂ§úÈùôÊò•Â±±Á©∫„ÄÇËøôÈ¶ñËØóÊèèÁªò‰∫ÜÊò•Â§©Â±±‰∏≠Èõ®ÂêéÁöÑÂØÇÈùô‰∏éÁ©∫ÁÅµÔºå-->
<!--                            Ë°®Áé∞Âá∫Ëá™ÁÑ∂ÁöÑÂÆÅÈùô‰∏éÂíåË∞êÁæé„ÄÇ-->
<!--                        </td>-->
<!--                    </tr>-->
<!--                    <tr>-->
<!--                        <th>LLaDA-Instruct</th>-->
<!--                        <td>‚ÄúÂ§úÈùôÊò•Â±±Á©∫‚ÄùÁöÑ‰∏ä‰∏ÄÂè•ÊòØ‚Äú‰∫∫Èó≤Ê°ÇËä±ËêΩ‚Äù</td>-->
<!--                    </tr>-->
<!--                </table>-->
<!--            </div>-->
<!--        </section>-->

        <section class="section" id="BibTeX">
            <div class="container is-max-desktop content">
                <h2 class="title">BibTeX</h2>
                Please consider cite our paper:
                <pre><code>Comming soon.</code></pre>
            </div>
        </section>

        <section class="section" id="refer">
            <div class="container is-max-desktop content">
                <h2 class="title">References</h2>
                <blockquote>
                    <p>
                        [1] Austin, J., Johnson, D. D., Ho, J., Tarlow, D., and
                        Van Den Berg, R. Structured denoising diffusion models
                        in discrete state-spaces. Advances in Neural Information
                        Processing Systems, 34:17981‚Äì17993, 2021a.
                    </p>
                    <p>
                        [2] Ou, J., Nie, S., Xue, K., Zhu, F., Sun, J., Li, Z.,
                        and Li, C. Your absorbing discrete diffusion secretly
                        models the conditional distributions of clean data.
                        arXiv preprint arXiv:2406.03736, 2024.
                    </p>
                    <p>
                        [3] Nie, S., Zhu, F., Du, C., Pang, T., Liu, Q., Zeng,
                        G., Lin, M., and Li, C. Scaling up masked diffusion
                        models on text. arXiv preprint arXiv:2410.18514, 2024.
                    </p>
                </blockquote>
            </div>
        </section>

    </body>
</html>
